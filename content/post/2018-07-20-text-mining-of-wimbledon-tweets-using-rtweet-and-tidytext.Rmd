---
title: Text mining of Wimbledon tweets using rtweet and tidytext
author: Jacquie Tran
date: '2018-07-20'
slug: text-mining-of-wimbledon-tweets-using-rtweet-and-tidytext
categories:
  - Off-field analyses
tags:
  - text mining
  - tennis
  - sports analytics
  - r stats
  - tidytext
  - rtweet
draft: yes
---

# New job, new skills
This year, I started in a new role as Senior Insights Researcher at High Performance Sport New Zealand. For me, one of the big drawcards of this role was the opportunity to learn and grow my skills and competencies as a performance sport professional.

Our team regularly deals with qualitative data, so as an applied sport scientist with a strongly quantitative training, it has been a steep learning curve but also enjoyable to open my mind up to different ways of thinking and knowing.

Online discussions about sports analytics seem heavily focused on numbers and what we can do with quantitative data. I remain just as interested in these discussions as I was before starting my current job, but I also see opportunities for more of us in the sports analytics community to think about what else we can learn by capturing and analysing qualitative data. In that spirit, this post is a brief glimpse at what is possible when applying text mining methods.

# Getting the data

I've been thinking about writing this post for a couple of months now, and every so often I trawl the internet looking for text corpuses that are relevant to sport - so far, my efforts have turned up fairly light results. (If anyone knowledgeable in this domain can point me to relevant open data sets, then [please get in touch!](https://www.twitter.com/jacquietran))

So...it's `rtweet` to the rescue!

<blockquote>
`rtweet` is a slick package by [Mike Kearney](https://www.twitter.com/kearneymw) (@kearneymw) for downloading tweets and associated metadata. The package website is a great place to start if you want to give it a crack: [https://rtweet.info/](https://rtweet.info/)
</blockquote>

When I started this blog post, Wimbledon 2018 was in its final days with the men's singles playing quarter finals and the women's singles playing semi finals. I used [this script](https://github.com/jacquietran/2018_wimbledon_tweets/blob/master/extract_wimby_tweets.R) to download tweets that:

- Included the keywords _'federer'_ or _'serena williams'_ (two separate searches),
- Were written in English, and
- Did not include retweets.

All I need to do here is load the libraries I need for this analysis and read the data sets into R from the CSV files stored in [this Github repo](https://github.com/jacquietran/2018_wimbledon_tweets).

``` {r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE)

```

``` {r load_libraries}

# Load libraries
library(readr)
library(dplyr)
library(tidytext)

```

``` {r import_data, message = FALSE}

# Read data into R
fed <- read_delim(
	"https://raw.githubusercontent.com/jacquietran/2018_wimbledon_tweets/master/fed.csv",
	delim = ",", col_names = TRUE, col_types = NULL)

serena <- read_delim(
	"https://raw.githubusercontent.com/jacquietran/2018_wimbledon_tweets/master/serena.csv",
	delim = ",", col_names = TRUE, col_types = NULL)

```

# Examining and cleaning the data

If you visually scan through the data set, you'll see it has several variables. For the purposes of this post, I am most interested in the following:

- `text`: The text content of a tweet.
- `favorite_count`: The number of times a tweet has been 'favourited' (or in modern Twitter parlance, 'liked'...ugh) by other user accounts
- `retweet_count`: The number of times a tweet has been 'retweeted' (shared) by other user accounts
- `followers_count`: The number of user accounts that follow the account who posted a tweet

<blockquote>
Not familiar with Twitter? Here's a quick primer that will help you get a lay of the land: [Mom, This is How Twitter Works](http://www.momthisishowtwitterworks.com/)
</blockquote>

We have our data and we know what variables we're going to focus on. How do we get from raw tweet data to text mining?

Enter: the `tidytext` package.

- Introduce `tidytext` package, point to book and tutorial(s)
- Fix text encoding if needed / remove emojis
- Remove stop words
- Note duplicate tweets

``` {r tidy_the_tweets}

# Remove URLs using regex
fed$text <- gsub("http[[:alnum:][:punct:]]*", "", fed$text)
serena$text <- gsub("http[[:alnum:][:punct:]]*", "", serena$text)
# Ref: http://www.rdatamining.com/books/rdm/faq/removeurlsfromtext

# Remove emojis
fed$text <- gsub("[^\x01-\x7F]", "", fed$text)
serena$text <- gsub("[^\x01-\x7F]", "", serena$text)
# Ref: https://stackoverflow.com/questions/44893354/remove-emoticons-in-r-using-tm-package

# Unnest tokens using tidytext
fed_tidy <- fed %>%
	select(user_id, status_id, screen_name,
				 favorite_count, retweet_count, followers_count, text) %>%
	unnest_tokens(word, text) %>%
	anti_join(stop_words)

serena_tidy <- serena %>%
	select(user_id, status_id, screen_name,
				 favorite_count, retweet_count, followers_count, text) %>%
	unnest_tokens(word, text) %>%
	anti_join(stop_words)

# Count most frequently occurring words
fed_tidy %>% count(word, sort = TRUE) %>% filter(!word %in% c("federer", "wimbledon"))


```

# n-gram frequency


# Sentiment analysis

- bing (positive / negative binary categorisation)
- AFINN (positive to negative, continuous scale)
- nrc (multiple sentiment categories)

# Correlating sentiment to favourites and retweets

# What else can text mining do?
- Sentiment analysis at the sentence level
- n-gram network analysis
- Parts-of-speech tagging
- Topic modelling